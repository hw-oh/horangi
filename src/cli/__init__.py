#!/usr/bin/env python
"""
Horangi CLI - í•œêµ­ì–´ LLM ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ë„êµ¬

ì‚¬ìš©ë²•:
    uv run horangi ko_hellaswag --model openai/gpt-4o -T limit=5
    uv run horangi ko_hellaswag --config gpt-4o -T limit=5
    uv run horangi swebench_verified_official_80 --config claude-3-5-sonnet -T limit=1
    uv run horangi --list  # ì‚¬ìš© ê°€ëŠ¥í•œ ë²¤ì¹˜ë§ˆí¬ ëª©ë¡
    uv run horangi --list-models  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„¤ì • ëª©ë¡
    uv run horangi leaderboard --project <entity>/<project>  # ë¦¬ë”ë³´ë“œ ìƒì„±
"""

import os
import re
import subprocess
import sys
from pathlib import Path


def _ensure_wandb_env() -> bool:
    """
    WANDB_ENTITYì™€ WANDB_PROJECT í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ì„¤ì •
    
    í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ë°›ì•„ ì„¤ì •í•©ë‹ˆë‹¤.
    
    Returns:
        True if í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë¨, False if ì‚¬ìš©ìê°€ ì·¨ì†Œ
    """
    entity = os.environ.get("WANDB_ENTITY")
    project = os.environ.get("WANDB_PROJECT")
    
    if entity and project:
        return True
    
    print("âš ï¸  W&B í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print()
    
    if not entity:
        try:
            entity = input("WANDB_ENTITY (íŒ€ ë˜ëŠ” ì‚¬ìš©ìëª…): ").strip()
            if not entity:
                print("âŒ WANDB_ENTITYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            os.environ["WANDB_ENTITY"] = entity
        except (EOFError, KeyboardInterrupt):
            print("\nâŒ ì·¨ì†Œë¨")
            return False
    
    if not project:
        try:
            project = input("WANDB_PROJECT (í”„ë¡œì íŠ¸ëª…): ").strip()
            if not project:
                print("âŒ WANDB_PROJECTê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            os.environ["WANDB_PROJECT"] = project
        except (EOFError, KeyboardInterrupt):
            print("\nâŒ ì·¨ì†Œë¨")
            return False
    
    print()
    print(f"âœ… í”„ë¡œì íŠ¸: {entity}/{project}")
    print()
    
    return True


def _is_openai_compat_api(model_config: dict) -> bool:
    """
    OpenAI í˜¸í™˜ APIì¸ì§€ í™•ì¸
    
    ë‹¤ìŒ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¥¼ ë§Œì¡±í•˜ë©´ OpenAI í˜¸í™˜ API:
    1. api_providerê°€ "openai"ì´ê³  base_urlì´ openai.comì´ ì•„ë‹Œ ê²½ìš°
    2. model_idê°€ "openai/"ë¡œ ì‹œì‘í•˜ê³  base_urlì´ openai.comì´ ì•„ë‹Œ ê²½ìš°
    
    ì˜ˆ: Solar, Grok, Together AI ë“±
    """
    api_provider = model_config.get("api_provider")
    model_id = model_config.get("model_id", "")
    base_url = model_config.get("base_url") or model_config.get("api_base")
    
    # api_providerê°€ openaiì´ê³  base_urlì´ openai.comì´ ì•„ë‹Œ ê²½ìš°
    if api_provider == "openai" and base_url:
        return "openai.com" not in base_url
    
    # ê¸°ì¡´ ë°©ì‹: openai/ providerë¥¼ ì‚¬ìš©í•˜ë©´ì„œ base_urlì´ openai.comì´ ì•„ë‹Œ ê²½ìš°
    if model_id.startswith("openai/") and base_url:
        return "openai.com" not in base_url
    
    return False


def _get_openai_compat_args(model_config: dict, verbose: bool = True) -> list[str]:
    """
    OpenAI í˜¸í™˜ APIë¥¼ ìœ„í•œ CLI ì¸ì ìƒì„±
    
    .envì˜ OPENAI_API_KEYê°€ ì•„ë‹Œ ëª¨ë¸ ì„¤ì •ì˜ api_key_envì—ì„œ ì½ì€ ê°’ì„
    --model-args api_key=...ë¡œ ì§ì ‘ ì „ë‹¬í•©ë‹ˆë‹¤.
    
    Returns:
        ì¶”ê°€í•  CLI ì¸ì ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["--model-args", "api_key=...", "--model-base-url", "..."])
    """
    extra_args = []
    
    if not _is_openai_compat_api(model_config):
        return extra_args
    
    # API í‚¤: -M api_key=... ë¡œ ì§ì ‘ ì „ë‹¬ (.env ìš°íšŒ)
    api_key_env = model_config.get("api_key_env")
    if api_key_env:
        api_key = os.environ.get(api_key_env)
        if api_key:
            extra_args.extend(["-M", f"api_key={api_key}"])
            if verbose:
                masked_key = api_key[:8] + "..." if len(api_key) > 8 else "***"
                print(f"ğŸ”‘ {api_key_env} â†’ -M api_key ({masked_key})")
        else:
            print(f"âŒ í™˜ê²½ë³€ìˆ˜ {api_key_env}ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print(f"   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”: export {api_key_env}=\"your-api-key\"")
    
    # Base URL: --model-base-url ë¡œ ì „ë‹¬
    base_url = model_config.get("base_url") or model_config.get("api_base")
    if base_url:
        extra_args.extend(["--model-base-url", base_url])
        if verbose:
            print(f"ğŸŒ --model-base-url â†’ {base_url}")
    
    return extra_args


def _handle_leaderboard_command(args: list[str]) -> int:
    """
    ë¦¬ë”ë³´ë“œ ìƒì„± ëª…ë ¹ì–´ ì²˜ë¦¬
    
    ì‚¬ìš©ë²•:
        horangi leaderboard --project <entity>/<project>
        horangi leaderboard --project <entity>/<project> --name "My Leaderboard"
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Weave ë¦¬ë”ë³´ë“œ ìƒì„±",
        prog="horangi leaderboard",
    )
    parser.add_argument(
        "--project", "-p",
        required=True,
        help="Weave í”„ë¡œì íŠ¸ (ì˜ˆ: my-team/my-project)",
    )
    parser.add_argument(
        "--name", "-n",
        default=None,
        help="ë¦¬ë”ë³´ë“œ ì´ë¦„ (ê¸°ë³¸: Korean LLM Leaderboard)",
    )
    parser.add_argument(
        "--description", "-d",
        default=None,
        help="ë¦¬ë”ë³´ë“œ ì„¤ëª…",
    )
    
    try:
        parsed = parser.parse_args(args)
    except SystemExit as e:
        return e.code if e.code else 0
    
    # í”„ë¡œì íŠ¸ì—ì„œ entityì™€ project ë¶„ë¦¬
    if "/" not in parsed.project:
        print("âŒ í”„ë¡œì íŠ¸ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. '<entity>/<project>' í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return 1
    
    entity, project = parsed.project.split("/", 1)
    
    print(f"ğŸ¯ Horangi - Weave ë¦¬ë”ë³´ë“œ ìƒì„±")
    print(f"ğŸ“ í”„ë¡œì íŠ¸: {entity}/{project}")
    print()
    
    # srcë¥¼ pathì— ì¶”ê°€
    src_path = Path(__file__).parent.parent
    sys.path.insert(0, str(src_path))
    
    from core.weave_leaderboard import (
        create_weave_leaderboard,
        LEADERBOARD_NAME,
        LEADERBOARD_DESCRIPTION,
    )
    
    name = parsed.name or LEADERBOARD_NAME
    description = parsed.description or LEADERBOARD_DESCRIPTION
    
    url = create_weave_leaderboard(
        name=name,
        description=description,
        entity=entity,
        project=project,
    )
    
    return 0 if url else 1


def main():
    args = sys.argv[1:]
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸° (src/cli/__init__.py -> í”„ë¡œì íŠ¸ ë£¨íŠ¸)
    project_root = Path(__file__).parent.parent.parent
    src_path = project_root / "src"
    horangi_py = project_root / "horangi.py"
    
    # srcë¥¼ pathì— ì¶”ê°€ (config_loader ë“± ì‚¬ìš© ìœ„í•´)
    sys.path.insert(0, str(src_path))
    
    # leaderboard: ë¦¬ë”ë³´ë“œ ìƒì„±
    if args and args[0] == "leaderboard":
        return _handle_leaderboard_command(args[1:])
    
    # --list-models: ëª¨ë¸ ì„¤ì • ëª©ë¡ ì¶œë ¥
    if args and args[0] == "--list-models":
        print("ğŸ¯ Horangi - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„¤ì •")
        print()
        
        from core.config_loader import ConfigLoader
        config = ConfigLoader()
        models = config.list_models()
        
        if not models:
            print("  ì„¤ì •ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"  configs/models/ ë””ë ‰í† ë¦¬ì— YAML íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„¤ì •:")
            print()
            for model_name in sorted(models):
                if model_name.startswith("_"):  # í…œí”Œë¦¿ íŒŒì¼ ì œì™¸
                    continue
                model_config = config.get_model(model_name)
                model_id = model_config.get("model_id", model_name)
                metadata = model_config.get("metadata", {})
                desc = metadata.get("description", "")
                release_date = metadata.get("release_date", "")
                
                print(f"  {model_name:<25} â†’ {model_id}")
                if desc:
                    print(f"  {'':25}   {desc}")
                if release_date:
                    print(f"  {'':25}   ì¶œì‹œì¼: {release_date}")
                print()
        
        print("ì‚¬ìš© ì˜ˆì‹œ:")
        print("  uv run horangi ko_hellaswag --config gpt-4o -T limit=5")
        return 0
    
    # --list ë˜ëŠ” -l ì˜µì…˜: ë²¤ì¹˜ë§ˆí¬ ëª©ë¡ ì¶œë ¥
    if not args or args[0] in ("--list", "-l", "--help", "-h"):
        print("ğŸ¯ Horangi - í•œêµ­ì–´ LLM ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ë„êµ¬")
        print()
        print("ì‚¬ìš©ë²•:")
        print("  uv run horangi <ë²¤ì¹˜ë§ˆí¬> --model <ëª¨ë¸> [ì˜µì…˜]")
        print("  uv run horangi <ë²¤ì¹˜ë§ˆí¬> --config <ì„¤ì •íŒŒì¼> [ì˜µì…˜]")
        print()
        print("ì˜ˆì‹œ:")
        print("  uv run horangi ko_hellaswag --model openai/gpt-4o -T limit=5")
        print("  uv run horangi ko_hellaswag --config gpt-4o -T limit=5")
        print("  uv run horangi swebench_verified_official_80 --config claude-3-5-sonnet -T limit=1")
        print()
        print("ëª¨ë¸ ì„¤ì • ëª©ë¡:")
        print("  uv run horangi --list-models")
        print()
        print("ë¦¬ë”ë³´ë“œ ìƒì„±:")
        print("  uv run horangi leaderboard --project <entity>/<project>")
        print()
        
        # ë²¤ì¹˜ë§ˆí¬ ëª©ë¡ ì¶œë ¥
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ë²¤ì¹˜ë§ˆí¬:")
        print()
        
        from benchmarks import list_benchmarks_with_descriptions
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        categories = {
            "ì¼ë°˜": ["ko_hellaswag", "ko_aime2025", "ifeval_ko", "ko_balt_700"],
            "ì§€ì‹": ["haerae_bench_v1_rc", "haerae_bench_v1_wo_rc", "kmmlu", "kmmlu_pro", "squad_kor_v1", "ko_truthful_qa"],
            "ì¶”ë¡ ": ["ko_moral", "ko_arc_agi", "ko_gsm8k"],
            "í¸í–¥/ì•ˆì „": ["korean_hate_speech", "kobbq", "ko_hle"],
            "í™˜ê° (HalluLens)": ["ko_hallulens_wikiqa", "ko_hallulens_longwiki", "ko_hallulens_generated", "ko_hallulens_mixed", "ko_hallulens_nonexistent"],
            "Function Calling": ["bfcl"],
            "ëŒ€í™”": ["mtbench_ko"],
            "ì½”ë”©": ["swebench_verified_official_80"],
        }
        
        benchmarks_dict = dict(list_benchmarks_with_descriptions())
        
        for category, names in categories.items():
            print(f"  [{category}]")
            for name in names:
                desc = benchmarks_dict.get(name, "")
                print(f"    {name:<35} {desc}")
            print()
        
        print(f"ì´ {len(benchmarks_dict)}ê°œ ë²¤ì¹˜ë§ˆí¬")
        return 0
    
    # ì²« ë²ˆì§¸ ì¸ìê°€ ë²¤ì¹˜ë§ˆí¬ ì´ë¦„
    benchmark = args[0]
    rest_args = list(args[1:])
    
    # --config ë˜ëŠ” -c ì˜µì…˜ ì²˜ë¦¬
    config_name = None
    new_args = []
    i = 0
    while i < len(rest_args):
        arg = rest_args[i]
        if arg in ("--config", "-c"):
            if i + 1 < len(rest_args):
                config_name = rest_args[i + 1]
                i += 2
                continue
            else:
                print("âŒ --config ì˜µì…˜ì— ëª¨ë¸ ì„¤ì • ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                print("   ì˜ˆ: --config gpt-4o")
                return 1
        new_args.append(arg)
        i += 1
    
    rest_args = new_args
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ëª¨ë¸ ì •ë³´ ë¡œë“œ
    if config_name:
        from core.config_loader import ConfigLoader
        
        config = ConfigLoader()
        model_config = config.get_model(config_name)
        
        if not model_config:
            print(f"âŒ ëª¨ë¸ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_name}")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(config.list_models())}")
            return 1
        
        # OpenAI í˜¸í™˜ API ì¸ì ìƒì„± (Solar, Grok ë“±)
        # .envì˜ OPENAI_API_KEY ëŒ€ì‹  ëª¨ë¸ ì„¤ì •ì˜ api_key_env ì‚¬ìš©
        openai_compat_args = _get_openai_compat_args(model_config)
        
        # model_idì™€ api_provider ì²˜ë¦¬
        # model_id: ì‚¬ìš©ìê°€ ë³´ëŠ” ì´ë¦„ (ì˜ˆ: upstage/solar-pro2)
        # api_provider: ì‹¤ì œ API provider (ì˜ˆ: openai - OpenAI í˜¸í™˜ API ì‚¬ìš© ì‹œ)
        model_id = model_config.get("model_id", config_name)
        api_provider = model_config.get("api_provider")
        
        if api_provider:
            # api_providerê°€ ì§€ì •ëœ ê²½ìš°: upstage/solar-pro2 â†’ openai/solar-pro2
            model_name = model_id.split("/")[-1]  # ëª¨ë¸ëª…ë§Œ ì¶”ì¶œ
            inspect_model = f"{api_provider}/{model_name}"
        else:
            inspect_model = model_id
        
        # ì´ë¯¸ --modelì´ ì§€ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì¶”ê°€
        has_model = any(arg == "--model" for arg in rest_args)
        if not has_model:
            rest_args = ["--model", inspect_model] + rest_args
        
        # ë²¤ì¹˜ë§ˆí¬ë³„ ì„¤ì • ì ìš©
        benchmark_overrides = model_config.get("benchmarks", {}).get(benchmark, {})
        defaults = model_config.get("defaults", {})
        
        # ì„¤ì • ì ìš© (-T ì˜µì…˜ìœ¼ë¡œ ì¶”ê°€, ì´ë¯¸ ì§€ì •ëœ ê²ƒì€ ìœ ì§€)
        existing_t_args = set()
        for j, arg in enumerate(rest_args):
            if arg == "-T" and j + 1 < len(rest_args):
                key = rest_args[j + 1].split("=")[0]
                existing_t_args.add(key)
        
        # defaults ì ìš©
        for key, value in defaults.items():
            if key not in existing_t_args and key in ("temperature", "max_tokens"):
                rest_args.extend(["-T", f"{key}={value}"])
        
        # ë²¤ì¹˜ë§ˆí¬ë³„ ì˜¤ë²„ë¼ì´ë“œ ì ìš©
        for key, value in benchmark_overrides.items():
            if key not in existing_t_args:
                rest_args.extend(["-T", f"{key}={value}"])
        
        # OpenAI í˜¸í™˜ API ì¸ì ì¶”ê°€ (api_key, base_url)
        rest_args.extend(openai_compat_args)
    
    # WANDB í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not _ensure_wandb_env():
        return 1
    
    # inspect eval ëª…ë ¹ êµ¬ì„±
    cmd = ["inspect", "eval", f"{horangi_py}@{benchmark}"] + rest_args
    
    # ì‹¤í–‰ (ì¶œë ¥ ìº¡ì²˜í•˜ì—¬ Weave Eval URL ì¶”ì¶œ)
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )
    
    weave_eval_url: str | None = None
    hook_noise_patterns = (
        r"^inspect_ai v",
        r"^- hooks enabled:",
        r"^\s*inspect_wandb/weave_evaluation_hooks:",
        r"^\s*inspect_wandb/wandb_models_hooks:",
        r"^\s*weave: Logged in as Weights & Biases user:",
        r"^\s*weave: View Weave data at https://wandb.ai/",
    )
    
    for line in process.stdout:
        # Weave Eval URL ì¶”ì¶œ
        m = re.search(r"ğŸ”—\s*Weave Eval:\s*(https?://\S+)", line)
        if m:
            weave_eval_url = m.group(1)
            continue  # URL ë¼ì¸ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ (ë§ˆì§€ë§‰ì— ì¶œë ¥)
        
        # ë…¸ì´ì¦ˆ ë¡œê·¸ í•„í„°ë§
        suppress = False
        for pat in hook_noise_patterns:
            if re.search(pat, line):
                suppress = True
                break
        
        if not suppress:
            print(line, end="", flush=True)
    
    process.wait()
    
    # í‰ê°€ ì™„ë£Œ í›„ Eval URL ì¶œë ¥
    if weave_eval_url:
        print()
        print(f"ğŸ”— Weave Eval: {weave_eval_url}")
    
    return process.returncode


if __name__ == "__main__":
    sys.exit(main())
